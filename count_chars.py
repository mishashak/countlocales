import os
import sys
import pandas as pd
import re
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment
from datetime import datetime
from tqdm import tqdm
import tempfile
import json
import shutil
from translations import t

# ì–¸ì–´ë³„ ì •ê·œ í‘œí˜„ì‹ íŒ¨í„´ ì •ì˜ ë° ê°„ê²°í•œ ì´ë¦„
PATTERNS = {
    'Korean': (re.compile(r'[ê°€-í£]'), 'ğŸ‡°ğŸ‡·'),
    'Alphabet': (re.compile(r'[A-Za-zÃ€-Ã¿]'), 'ğŸ‡ºğŸ‡¸'),
    'Number': (re.compile(r'[0-9]'), 'ğŸ”¢'),
    'Chinese': (re.compile(r'[\u4E00-\u9FFF]'), 'ğŸ‡¨ğŸ‡³'),
    'Japanese': (re.compile(r'[\u30A0-\u30FF\u3040-\u309F]'), 'ğŸ‡¯ğŸ‡µ'),
    'Thai': (re.compile(r'[\u0E00-\u0E7F]'), 'ğŸ‡¹ğŸ‡­'),
    'Russian': (re.compile(r'[\u0400-\u04FF]'), 'ğŸ‡·ğŸ‡º'),  # í‚¤ë¦´ ë¬¸ì ì¶”ê°€
    'Special': (re.compile(r'[^\w\s]'), 'ğŸ”£')
}

# ì„ì‹œ íŒŒì¼ ê´€ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤
class TempFileManager:
    def __init__(self, base_dir):
        self.base_dir = base_dir
        self.temp_dir = tempfile.mkdtemp(dir=base_dir)
        self.temp_files = {lang: [] for lang in PATTERNS}
        self.current_sets = {lang: set() for lang in PATTERNS}
        self.set_size_limit = 100000  # ê° ì–¸ì–´ë³„ ì§‘í•© í¬ê¸° ì œí•œ

    def add_text(self, lang, text):
        if text in self.current_sets[lang]:
            return
        
        self.current_sets[lang].add(text)
        if len(self.current_sets[lang]) >= self.set_size_limit:
            self._save_to_temp_file(lang)

    def _save_to_temp_file(self, lang):
        if not self.current_sets[lang]:
            return

        temp_file = os.path.join(self.temp_dir, f"{lang}_{len(self.temp_files[lang])}.json")
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(list(self.current_sets[lang]), f, ensure_ascii=False)
        
        self.temp_files[lang].append(temp_file)
        self.current_sets[lang].clear()

    def get_all_unique_texts(self, lang):
        all_texts = set()
        
        # í˜„ì¬ ë©”ëª¨ë¦¬ì— ìˆëŠ” í…ìŠ¤íŠ¸ ì¶”ê°€
        all_texts.update(self.current_sets[lang])
        
        # ì„ì‹œ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë¡œë“œ
        for temp_file in self.temp_files[lang]:
            with open(temp_file, 'r', encoding='utf-8') as f:
                all_texts.update(json.load(f))
        
        return all_texts

    def get_total_chars(self, lang):
        total_chars = 0
        unique_texts = self.get_all_unique_texts(lang)
        for text in unique_texts:
            counts = count_characters(text)
            total_chars += counts[lang]
        return total_chars

    def cleanup(self):
        """ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ (Windows ì•¡ì„¸ìŠ¤ ê±°ë¶€ ì˜¤ë¥˜ ì²˜ë¦¬)"""
        import time
        import stat
        
        def handle_remove_readonly(func, path, exc):
            """ì½ê¸° ì „ìš© íŒŒì¼ ì‚­ì œë¥¼ ìœ„í•œ í•¸ë“¤ëŸ¬"""
            os.chmod(path, stat.S_IWRITE)
            func(path)
        
        max_retries = 3
        retry_delay = 0.5
        
        for attempt in range(max_retries):
            try:
                if os.path.exists(self.temp_dir):
                    shutil.rmtree(self.temp_dir, onerror=handle_remove_readonly)
                break
            except (PermissionError, OSError) as e:
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    retry_delay *= 2  # ì§€ìˆ˜ ë°±ì˜¤í”„
                else:
                    # ìµœì¢… ì‹œë„ ì‹¤íŒ¨ ì‹œ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
                    print(f"Warning: Could not delete temporary directory {self.temp_dir}: {e}")
                    print(f"Please manually delete it if needed.")

def count_characters(text):
    counts = {lang: 0 for lang in PATTERNS}
    for lang, (pattern, _) in PATTERNS.items():
        matches = pattern.findall(text)
        counts[lang] += len(matches)
    return counts

def determine_primary_language(counts):
    non_special_counts = {lang: count for lang, count in counts.items() if lang not in ['Special']}
    non_english_counts = {lang: count for lang, count in non_special_counts.items() if lang != ['Alphabet']}

    if sum(non_special_counts.values()) == 0:
        # íŠ¹ìˆ˜ ë¬¸ìì™€ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°
        primary_lang = max(non_special_counts, key=non_special_counts.get)
    elif sum(non_english_counts.values()) > 0:
        # ì˜ì–´ ì™¸ì— ë‹¤ë¥¸ ì–¸ì–´ê°€ ìˆëŠ” ê²½ìš°
        primary_lang = max(non_english_counts, key=non_english_counts.get)
    else:
        # ì˜ì–´ë§Œ ìˆëŠ” ê²½ìš°
        primary_lang = 'Alphabet'
    
    return primary_lang

def analyze_sheet(df):
    total_counts = {lang: 0 for lang in PATTERNS}
    column_counts = {col: {lang: 0 for lang in PATTERNS} for col in range(df.shape[1])}

    for r in range(df.shape[0]):
        for c in range(df.shape[1]):
            cell_value = df.iat[r, c]
            if pd.isna(cell_value) or str(cell_value).strip() == '':
                continue  # ë¹ˆ ì…€ì€ ë¬´ì‹œ
            text = str(cell_value)
            counts = count_characters(text)
            
            # ëª¨ë“  ì–¸ì–´ì˜ ê¸€ì ìˆ˜ë¥¼ ë”í•¨
            for lang in PATTERNS:
                total_counts[lang] += counts[lang]
                column_counts[c][lang] += counts[lang]

    # ìœ íš¨í•œ ì—´ë§Œ í•„í„°ë§
    valid_columns = []
    empty_col_count = 0
    for col in range(df.shape[1]):
        col_total = sum(column_counts[col].values())
        if col_total > 0:
            valid_columns.append(col)
            empty_col_count = 0
        else:
            empty_col_count += 1
            if empty_col_count >= 20:  # ë¹ˆ ì—´ì´ 20ê°œ ì´ìƒ ì—°ì†ë  ê²½ìš° ì¤‘ë‹¨
                break

    return total_counts, column_counts, valid_columns

def adjust_column_widths(sheet):
    for column_cells in sheet.columns:
        max_length = 0
        column = column_cells[0].column_letter  # Get the column name
        
        # Summary_cell_address ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì—´(Aì—´, Bì—´ ë“±)ë§Œ ë„ˆë¹„ë¥¼ 10ìœ¼ë¡œ ê³ ì •í•˜ê³  ì…€ì— ë§ì¶¤ ì„¤ì •
        if sheet.title == 'Summary_cell_address' and column >= 'G':  # Gì—´ë¶€í„° ì‹œì‘í•˜ëŠ” ë°ì´í„° ì—´
            sheet.column_dimensions[column].width = 10
            # í•´ë‹¹ ì—´ì˜ ëª¨ë“  ì…€ì— ì…€ì— ë§ì¶¤ ì„¤ì • ì ìš© (ì¤„ë°”ê¿ˆ ì—†ìŒ)
            for cell in column_cells:
                cell.alignment = Alignment(wrap_text=False, shrink_to_fit=True)
            continue
            
        for cell in column_cells:
            try:
                if len(str(cell.value)) > max_length:
                    max_length = len(str(cell.value))
            except:
                pass
        adjusted_width = (max_length + 2)
        sheet.column_dimensions[column].width = adjusted_width

def get_unique_values_per_column(df):
    unique_counts = {}
    for col in range(df.shape[1]):
        # í•´ë‹¹ ì—´ì˜ ëª¨ë“  ê°’ì„ ê°€ì ¸ì˜´
        column_values = df.iloc[:, col].dropna().astype(str)
        # ì¤‘ë³µ ì œê±°
        unique_values = column_values.unique()
        # ê° ê³ ìœ  ê°’ì— ëŒ€í•´ ê¸€ì ìˆ˜ë¥¼ ì„¸ê³  í•©ì‚°
        col_counts = {lang: 0 for lang in PATTERNS}
        for value in unique_values:
            counts = count_characters(value)
            for lang in PATTERNS:
                col_counts[lang] += counts[lang]
        unique_counts[col] = col_counts
    return unique_counts

def get_cell_addresses(df):
    cell_addresses = {lang: {col: [] for col in range(df.shape[1])} for lang in PATTERNS}
    
    for r in range(df.shape[0]):
        for c in range(df.shape[1]):
            cell_value = df.iat[r, c]
            if pd.isna(cell_value) or str(cell_value).strip() == '':
                continue  # ë¹ˆ ì…€ì€ ë¬´ì‹œ
                
            text = str(cell_value)
            for lang, (pattern, _) in PATTERNS.items():
                if pattern.search(text):
                    cell_address = f"{get_column_letter(c+1)}{r+1}"
                    cell_addresses[lang][c].append(cell_address)
    
    # ê° ì–¸ì–´ë³„ë¡œ ì…€ ì£¼ì†Œ ì •ë ¬
    for lang in PATTERNS:
        for col in range(df.shape[1]):
            cell_addresses[lang][col].sort(key=lambda x: (x[0], int(x[1:])))
    
    return cell_addresses

def count_cells_by_language(df):
    cell_counts = {lang: {col: 0 for col in range(df.shape[1])} for lang in PATTERNS}
    
    for r in range(df.shape[0]):
        for c in range(df.shape[1]):
            cell_value = df.iat[r, c]
            if pd.isna(cell_value) or str(cell_value).strip() == '':
                continue  # ë¹ˆ ì…€ì€ ë¬´ì‹œ
                
            text = str(cell_value)
            for lang, (pattern, _) in PATTERNS.items():
                if pattern.search(text):
                    cell_counts[lang][c] += 1
    
    return cell_counts

def main(current_language='ko'):
    # exe íŒŒì¼ì´ ì‹¤í–‰ëœ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
    folder_path = os.path.dirname(os.path.abspath(sys.executable)) if getattr(sys, 'frozen', False) else os.path.dirname(os.path.abspath(__file__))
    print(f"{t('UI_006', current_language)}: {folder_path}")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_name = f"CHAR_COUNT_REPORT_{timestamp}.xlsx"
    report_path = os.path.join(folder_path, report_name)
    print(f"{t('UI_007', current_language)}: {report_path}")

    report_wb = Workbook()
    
    # Summary_real ì‹œíŠ¸ ìƒì„±
    report_ws_real = report_wb.active
    report_ws_real.title = 'Summary_real'
    
    # Summary_unique_for_Sheet ì‹œíŠ¸ ìƒì„±
    report_ws_unique_for_sheet = report_wb.create_sheet('Summary_unique_for_Sheet')
    
    # Summary_unique_for_Folder ì‹œíŠ¸ ìƒì„±
    report_ws_unique_for_folder = report_wb.create_sheet('Summary_unique_for_Folder')
    
    # Summary_cell_address ì‹œíŠ¸ ìƒì„±
    report_ws_cell_address = report_wb.create_sheet('Summary_cell_address')
    
    # Summary_cells ì‹œíŠ¸ ìƒì„±
    report_ws_cells = report_wb.create_sheet('Summary_cells')

    # ì„ì‹œ íŒŒì¼ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    temp_manager = TempFileManager(folder_path)

    # í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•œ ëª¨ë“  ì—‘ì…€ íŒŒì¼ ìˆ˜ì§‘
    files_to_process = []
    for root, dirs, files in os.walk(folder_path):
        # íŠ¹ì • í´ë” ì œì™¸
        if '__pycache__' in dirs:
            dirs.remove('__pycache__')
        if '.git' in dirs:
            dirs.remove('.git')
            
        for file in files:
            if file.endswith(('.xlsx', '.xlsm', '.csv')) and "REPORT_" not in file and not file.startswith('~$'):
                # ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
                rel_path = os.path.relpath(os.path.join(root, file), folder_path)
                files_to_process.append((rel_path, file))

    print(f"{t('UI_008', current_language)}: {[f[1] for f in files_to_process]}")

    # ì „ì²´ ì—´ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
    all_columns = set()
    processed_files = 0

    print(t('UI_009', current_language).format(len(files_to_process)))
    print(t('UI_010', current_language))

    data_rows_real = []  # ì‹¤ì œ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    data_rows_unique_for_sheet = []  # ê³ ìœ  ê°’ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    data_rows_cell_address = []  # ì…€ ì£¼ì†Œ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    data_rows_cells = []  # ì…€ ê°¯ìˆ˜ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    # ì½˜ì†” ì¶œë ¥ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    has_console = hasattr(sys.stdout, 'write') and sys.stdout is not None
    
    for rel_path, file_name in tqdm(files_to_process, desc="processing files", disable=not has_console):
        try:
            print(f"\n{t('UI_011', current_language)}: {file_name}")
            file_path = os.path.join(folder_path, rel_path)
            xls = pd.ExcelFile(file_path)

            for sheet_name in xls.sheet_names:
                print(f"{t('UI_012', current_language)}: {sheet_name}")
                df = pd.read_excel(xls, sheet_name=sheet_name, header=None)
                total_counts, column_counts, valid_columns = analyze_sheet(df)
                unique_counts = get_unique_values_per_column(df)
                cell_addresses = get_cell_addresses(df)
                cell_counts = count_cells_by_language(df)

                # ìœ íš¨í•œ ì—´ì„ ì „ì²´ ì—´ ëª©ë¡ì— ì¶”ê°€
                for col in valid_columns:
                    all_columns.add(col)

                # ê³ ìœ í•œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (í´ë” ì „ì²´ ê¸°ì¤€)
                for r in range(df.shape[0]):
                    for c in range(df.shape[1]):
                        cell_value = df.iat[r, c]
                        if pd.isna(cell_value) or str(cell_value).strip() == '':
                            continue
                        text = str(cell_value)
                        for lang, (pattern, _) in PATTERNS.items():
                            if pattern.search(text):
                                temp_manager.add_text(lang, text)

                # ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬
                for lang in PATTERNS:
                    emoji = PATTERNS[lang][1]
                    col_totals = [column_counts[col][lang] for col in valid_columns]
                    total = total_counts[lang]
                    sum_col_totals = sum(col_totals)
                    if sum_col_totals != total:
                        status = f"Error: Total characters({total}) and column totals({sum_col_totals}) do not match"
                    else:
                        status = "Normal"

                    row_data = [rel_path, file_name, sheet_name, status, emoji, f"{lang}", total] + col_totals
                    data_rows_real.append(row_data)

                # ê³ ìœ  ê°’ ë°ì´í„° ì²˜ë¦¬
                for lang in PATTERNS:
                    emoji = PATTERNS[lang][1]
                    unique_col_totals = [unique_counts[col][lang] for col in valid_columns]
                    total_unique = sum(unique_col_totals)
                    row_data = [rel_path, file_name, sheet_name, "Normal", emoji, f"{lang}", total_unique] + unique_col_totals
                    data_rows_unique_for_sheet.append(row_data)
                
                # ì…€ ì£¼ì†Œ ë°ì´í„° ì²˜ë¦¬
                for lang in PATTERNS:
                    emoji = PATTERNS[lang][1]
                    cell_col_addresses = [', '.join(cell_addresses[lang][col]) for col in valid_columns]
                    total_cells = sum(len(cell_addresses[lang][col]) for col in valid_columns)
                    row_data = [rel_path, file_name, sheet_name, "Normal", emoji, f"{lang}", total_cells] + cell_col_addresses
                    data_rows_cell_address.append(row_data)
                
                # ì…€ ê°¯ìˆ˜ ë°ì´í„° ì²˜ë¦¬
                for lang in PATTERNS:
                    emoji = PATTERNS[lang][1]
                    cell_col_counts = [cell_counts[lang][col] for col in valid_columns]
                    total_cells = sum(cell_col_counts)
                    row_data = [rel_path, file_name, sheet_name, "Normal", emoji, f"{lang}", total_cells] + cell_col_counts
                    data_rows_cells.append(row_data)

            processed_files += 1
            print(t('UI_013', current_language).format(f"{processed_files}/{len(files_to_process)}"))

        except Exception as e:
            print(f"{t('UI_017', current_language)}: {file_name} {t('UI_018', current_language)}: {e}")
            continue

    print(f"\n{t('UI_014', current_language)}")
    # Summary_real ì‹œíŠ¸ì˜ í—¤ë” ì¶”ê°€
    sorted_columns = sorted(all_columns)
    column_headers = [f"Col {get_column_letter(col+1)}" for col in sorted_columns]
    headers = ['Path', 'FileName', 'SheetName', 'Status', 'ğŸ³ï¸', 'Char', 'TotalChars'] + column_headers
    
    # Summary_real ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€
    report_ws_real.append(headers)
    for row in data_rows_real:
        report_ws_real.append(row)
    adjust_column_widths(report_ws_real)

    # Summary_unique_for_Sheet ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€
    report_ws_unique_for_sheet.append(headers)
    for row in data_rows_unique_for_sheet:
        report_ws_unique_for_sheet.append(row)
    adjust_column_widths(report_ws_unique_for_sheet)
    
    # Summary_unique_for_Folder ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€
    report_ws_unique_for_folder.append(headers)
    for lang in PATTERNS:
        emoji = PATTERNS[lang][1]
        # count_characters í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸€ì ìˆ˜ ê³„ì‚°
        total_chars = temp_manager.get_total_chars(lang)
        row_data = ['ALL', 'ALL', 'ALL', 'Normal', emoji, f"{lang}", total_chars] + [0] * len(sorted_columns)
        report_ws_unique_for_folder.append(row_data)
    adjust_column_widths(report_ws_unique_for_folder)
    
    # Summary_cell_address ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€
    cell_address_headers = headers.copy()
    cell_address_headers[5] = 'TotalCells'  # F1 ì…€ì˜ í—¤ë” ë³€ê²½
    report_ws_cell_address.append(cell_address_headers)
    for row in data_rows_cell_address:
        report_ws_cell_address.append(row)
    adjust_column_widths(report_ws_cell_address)
    
    # Summary_cells ì‹œíŠ¸ì— ë°ì´í„° ì¶”ê°€
    cells_headers = headers.copy()
    cells_headers[5] = 'TotalCells'  # F1 ì…€ì˜ í—¤ë” ë³€ê²½
    report_ws_cells.append(cells_headers)
    for row in data_rows_cells:
        report_ws_cells.append(row)
    adjust_column_widths(report_ws_cells)

    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    temp_manager.cleanup()

    report_wb.save(report_path)
    print(f"{t('UI_015', current_language)}: {report_path}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"Error: {e}")
        input("Press any key to continue...")
